---
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: Group Name's Group Project
execute:
  echo: false
format:
  html:
    theme:
      - minty
      - css/web.scss
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: Spectral
    sansfont: Roboto
    monofont: JetBrainsMono-Regular
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

## Declaration of Authorship {.unnumbered .unlisted}

We, [insert your group's names], confirm that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.

Date:

Student Numbers: 

## Brief Group Reflection

| What Went Well | What Was Challenging |
| -------------- | -------------------- |
| A              | B                    |
| C              | D                    |

## Priorities for Feedback

Are there any areas on which you would appreciate more detailed feedback if we're able to offer it?

```{=html}
<style type="text/css">
.duedate {
  border: dotted 2px red; 
  background-color: rgb(255, 235, 235);
  height: 50px;
  line-height: 50px;
  margin-left: 40px;
  margin-right: 40px
  margin-top: 10px;
  margin-bottom: 10px;
  color: rgb(150,100,100);
  text-align: center;
}
</style>
```

{{< pagebreak >}}

# Response to Questions
https://github.com/songzimen/FSDS_Deprivation_Airbnb_GWR.git

```{python}
# Import libs

import esda  
import pandas as pd
import geopandas as gpd
from geopandas import GeoDataFrame
import libpysal as lps
import numpy as np
import matplotlib.pyplot as plt
from shapely.geometry import Point
import contextily as ctx
from pylab import figure, scatter, show
%matplotlib inline
from splot.esda import plot_moran
from splot.esda import moran_scatterplot
from esda.moran import Moran_Local
from splot.esda import lisa_cluster
from splot.esda import plot_local_autocorrelation
from mgwr.sel_bw import Sel_BW
from mgwr.gwr import GWR, MGWR
import seaborn as sns
from scipy.stats import gaussian_kde
import mapclassify as mc
```

```{python}
# Load & merge: airbnb and deprivation

airbnb=pd.read_csv("data/grouped_data.csv")[['GSS_CODE','Count_','average_price']]
dep=pd.read_excel("data/2019_deprivation.xlsx").drop(columns=['old_ward_code'])
dep.rename(columns={'NEW_CODE':'GSS_CODE'},inplace=True)

rawData=pd.merge(dep, airbnb, on='GSS_CODE', how='inner')
rawData['average_price'] = pd.to_numeric(rawData['average_price'], errors='coerce')
display(rawData)
```

```{python}
# Load & plot: London ward (city merged)
# Merge & View: data & map

map=gpd.read_file('data/London_Ward_CityMerged.shp')[['GSS_CODE','geometry']]
myData=pd.merge(rawData, map, on='GSS_CODE', how='inner')
myData=gpd.GeoDataFrame(myData)
# myData.to_csv('data.csv',index=False)
```

## 1. Who collected the data?

::: {.duedate}

( 2 points; Answer due Week 7 )

:::

An inline citation: As discussed on @insideairbnb, there are many...

A parenthetical citation: There are many ways to research Airbnb [see, for example, @insideairbnb]... 

## 2. Why did they collect it?

::: {.duedate}

( 4 points; Answer due Week 7 )

:::

## 3. How was the data collected?  

::: {.duedate}

( 5 points; Answer due Week 8 )

:::

## 4. How does the method of collection impact the completeness and/or accuracy of its representation of the process it seeks to study, and what wider issues does this raise?

::: {.duedate}

( 11 points; Answer due Week 9 )

:::

## 5. What ethical considerations does the use of this data raise? 

::: {.duedate}

( 18 points; Answer due {{< var assess.group-date >}} )

:::

## 6. With reference to the data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and Listing types suggest about the nature of Airbnb lets in London? 

::: {.duedate}

( 15 points; Answer due {{< var assess.group-date >}} )

:::

```{python}
def get_statistics_feature(data,name):
    column_values=data[name]
    
    mean = column_values.mean()
    std = column_values.std()
    median = column_values.median()
    quartiles = column_values.quantile([0.25, 0.5, 0.75])
    
    plt.figure(figsize=(10, 5))
    
    plt.subplot(1, 2, 1)
    sns.boxplot(y=column_values)
    plt.title(f'Boxplot of {name}')
    
    plt.subplot(1, 2, 2)
    sns.histplot(column_values, kde=True)
    plt.axvline(mean, color='r', linestyle='--', label=f'Mean: {mean:.2f}')
    plt.axvline(median, color='g', linestyle='-', label=f'Median: {median:.4f}')
    plt.xlabel('Values')
    plt.ylabel('Frequency')
    plt.legend()
    plt.title(f'Distribution of {name}')
    
    plt.tight_layout()
    plt.show()
    print(f'The standard deviation of {name} is: {std}')
```

```{python}
get_statistics_feature(rawData,"Count_")
get_statistics_feature(rawData,"average_price")
```

```{python}
def get_kde(airbnb_gdf,map):
    airbnb_gdf = airbnb_gdf.to_crs(epsg=3857)
    myMap = map.to_crs(epsg=3857)
    
    # calculate KDE
    
    longitude = airbnb_gdf.geometry.x
    latitude = airbnb_gdf.geometry.y
    
    xy = np.vstack([longitude, latitude])
    kde = gaussian_kde(xy, bw_method= 'silverman') # bw_method='scott' bw_method='silverman' bw_method=0.1
    
    grid_x, grid_y = np.mgrid[longitude.min():longitude.max():200j, latitude.min():latitude.max():200j]
    grid_coords = np.vstack([grid_x.ravel(), grid_y.ravel()])
    z = kde(grid_coords).reshape(grid_x.shape)
    
    # plot
    
    fig, ax = plt.subplots(figsize=(20, 20))
    
    # plot London borough
    myMap.plot(ax=ax, color='none', edgecolor='black', zorder=2)
    
    # plot kernel density layers
    im = ax.imshow(z, origin='lower', extent=[longitude.min(), longitude.max(), latitude.min(), latitude.max()], cmap=plt.cm.hot_r, alpha=0.6, zorder=3)
    
    # plot OpenStreetMap 
    ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik, zorder=1)
    
    # adjusting the axes to fit the drawing
    ax.set_xlim(longitude.min(), longitude.max())
    ax.set_ylim(latitude.min(), latitude.max())
    
    # add a colour bar
    cbar = plt.colorbar(im, ax=ax, orientation='vertical', fraction=0.036, pad=0.04)
    cbar.set_label('Density')
    
    # set x,y axis
    ax.set_xlabel('Longitude')
    ax.set_ylabel('Latitude')
    
    # set title
    ax.set_title('Airbnb Hotspots in London with OpenStreetMap Basemap')
    
    plt.show()
    
listData = pd.read_csv('data/listings.csv')
geometry = [Point(xy) for xy in zip(listData['longitude'], listData['latitude'])]
crs = {'init': 'epsg:4326'} 
airbnb_gdf = gpd.GeoDataFrame(listData, geometry=geometry, crs=crs)
get_kde(airbnb_gdf,map)
```

## 7. Drawing on your previous answers, and supporting your response with evidence (e.g. figures, maps, and statistical analysis/models), how *could* this data set be used to inform the regulation of Short-Term Lets (STL) in London? 

::: {.duedate}

( 45 points; Answer due {{< var assess.group-date >}} )

:::

```{python}
# Calculate Gloval Moran's I


def global_moran(myData, columnName):
    gdf = myData[[columnName, "geometry"]]

    ax = myData.plot(figsize=(8, 8), column=columnName,legend=True)
    ax.set_axis_off()
    plt.savefig('average_price_for_' + columnName + '.png')

    wq = lps.weights.Queen.from_dataframe(gdf)
    wq.transform = "r"
    centroids = gdf.geometry.centroid
    # fig = figure(figsize=(8, 8))
    # ax = gdf.plot(figsize=(8, 8), cmap="Blues")
    # plt.plot(centroids.x, centroids.y, ".")
    # for k, neighs in wq.neighbors.items():
    #     # print(k,neighs)
    #     origin = centroids[k]
    #     for neigh in neighs:
    #         segment = centroids[[k, neigh]]
    #         # plt.plot(segment.x, segment.y, "-")
    plt.axis("off")
    plt.savefig('weight_matrix_for_' + columnName + '.png')
    plt.show()

    y = gdf[columnName]
    mi = esda.moran.Moran(y, wq)

    print("Global Moran's Iï¼š", mi.I)
    print("The z-test value under random distribution hypothesis: ", mi.z_rand)
    print("The p-value of the z-test under random distribution hypothesis: ", mi.p_rand)
    print("The z-test value under normal distribution hypothesis: ", mi.z_norm)
    print("The p-value of the Z test under normal distribution hypothesis: ", mi.p_norm)

    plot_moran(mi, zstandard=True, figsize=(10, 4))
    plt.legend(['Moran Scatter'])
    plt.savefig('Moran Scatter_for_' + columnName + '.png')
    plt.show()
```

```{python}
global_moran(myData, "average_price")
global_moran(myData, "Count_")
```

```{python}
# GWR

def run_gwr(myData,y_column,x_column):
    gdf=myData[[y_column,x_column,'geometry']]
    gdf['centro']=gdf.geometry.centroid
    gdf['X']=gdf.centro.x
    gdf['Y']=gdf.centro.y
    coords = list(zip(gdf['X'],gdf['Y']))
    
    y=gdf[y_column].values.reshape((-1,1))
    y = (y - y.mean(axis=0)) / y.std(axis=0)
    X=gdf[[x_column]].values
    X = (X - X.mean(axis=0)) / X.std(axis=0)
    
    sel = Sel_BW(coords, y, X)
    bw = sel.search()
    print('bw:', bw)
    gwr = GWR(coords, y, X, bw)
    gwr_results = gwr.fit()
    print('aicc:', gwr_results.aicc)
    print('ENP:', gwr_results.ENP)
    print('sigma2:', gwr_results.sigma2)

# The following code throws an error and interrupt on some of our group members' computer while others are not. 
# If an error occurs, please comment the next line, so that the output of coefficient visualisation would not be affected.
    print(gwr_results.summary())
    
    gdf['coe'] = gwr_results.params[:, 1]
    # gdf['r2'] = gwr_results.localR2
    # gdf['r2'] = np.clip(gdf['r2'], -1, 1)

    # classifier_r2 = mc.NaturalBreaks(y=myData[y_column], k=5)
    classifier_coe = mc.NaturalBreaks(y=myData[x_column], k=5)

    # gdf['r2_classified'] = gdf['r2'].apply(classifier_r2)
    gdf['coe_classified'] = gdf['coe'].apply(classifier_coe)
    
    fig, ax = plt.subplots(1,figsize=(18, 9))
    # gdf.plot(column='r2', cmap='coolwarm', legend=True, ax=ax[0])
    gdf.plot(column='coe', cmap='coolwarm', legend=True, ax=ax[1])
    # ax[0].set_title('GWR R2 Result '+ y_column+'~'+x_column)
    # ax[0].axis('off')
    ax[0].set_title('GWR Result '+ y_column+'~'+x_column)
    ax[0].axis('off')
    plt.savefig(f"{x_column}~{y_column}.png")
    plt.show()
```

```{python}
run_gwr(myData,"average_price","Income Score (rate)")
run_gwr(myData,"average_price","Employment Score (rate)")
run_gwr(myData,"average_price","Education, Skills and Training Score")
run_gwr(myData,"average_price","Health Deprivation and Disability Score")
run_gwr(myData,"average_price","Crime Score")
run_gwr(myData,"average_price","Barriers to Housing and Services Score")
run_gwr(myData,"average_price","Living Environment Score")
```

```{python}
run_gwr(myData,"Count_","Income Score (rate)")
run_gwr(myData,"Count_","Employment Score (rate)")
run_gwr(myData,"Count_","Education, Skills and Training Score")
run_gwr(myData,"Count_","Health Deprivation and Disability Score")
run_gwr(myData,"Count_","Crime Score")
run_gwr(myData,"Count_","Barriers to Housing and Services Score")
run_gwr(myData,"Count_","Living Environment Score")
```

## Sustainable Authorship Tools

Your QMD file should automatically download your BibTeX file. We will then re-run the QMD file to generate the output successfully.

Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style="font-family:Sans-Serif;">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). 

## References
